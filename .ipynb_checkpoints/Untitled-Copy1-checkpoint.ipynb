{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6388f00-fb73-4d9e-babb-a91462fc22b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import L2\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1563e0f-f476-449b-a27b-db56421d9bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('data/processedX.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d71f0e4-1b2f-4209-a57b-03bfa235ef08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract temperature and humidity columns\n",
    "temp_columns = [col for col in data.columns if 'temperature_2m' in col]\n",
    "hum_columns = [col for col in data.columns if 'relative_humidity_2m' in col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ea79cbd-dc85-4f7e-9ae0-c20e778a8fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "scaler_temp = MinMaxScaler()\n",
    "scaler_hum = MinMaxScaler()\n",
    "scaled_temp = scaler_temp.fit_transform(data[temp_columns])\n",
    "scaled_hum = scaler_hum.fit_transform(data[hum_columns])\n",
    "scaled_data = np.hstack((scaled_temp, scaled_hum))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0e4a074-2b1a-4844-93a4-5b0a8e36db45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences for time series forecasting\n",
    "def create_sequences(data, lookback=30):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(data) - lookback):\n",
    "        sequences.append(data[i:i + lookback])\n",
    "        targets.append(data[i + lookback])\n",
    "    return np.array(sequences), np.array(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d66e1ba-cfef-40be-bf17-7684513f4561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences\n",
    "X, y = create_sequences(scaled_data, lookback=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60f19c0f-bb29-45e5-815c-631a9d1be3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e3517cc-5305-4e22-89c4-9e2d917b52c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\21623\\Documents\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define a more complex LSTM model\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(256, activation='relu', return_sequences=True,\n",
    "                       input_shape=(X_train.shape[1], X_train.shape[2]), kernel_regularizer=L2(0.001))),\n",
    "    Dropout(0.4),\n",
    "    Bidirectional(LSTM(256, activation='relu', return_sequences=True, kernel_regularizer=L2(0.001))),\n",
    "    Dropout(0.4),\n",
    "    Bidirectional(LSTM(128, activation='relu')),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(14)  # 7 temperature + 7 humidity predictions\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f52e1fc6-8ee7-48c1-bba7-096280d00d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee179e90-f05e-4f26-9935-9b73cd6adaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks for early stopping and learning rate reduction\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece8b87f-5b21-486a-9e03-86ea878e5698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 402ms/step - loss: 1.6740 - val_loss: 1.2928 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 377ms/step - loss: 1.2561 - val_loss: 1.0933 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 378ms/step - loss: 1.0548 - val_loss: 0.9303 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 375ms/step - loss: 0.8958 - val_loss: 0.7827 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 397ms/step - loss: 0.7530 - val_loss: 0.6519 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 363ms/step - loss: 0.6289 - val_loss: 0.5464 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 353ms/step - loss: 0.5291 - val_loss: 0.4595 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 350ms/step - loss: 0.4463 - val_loss: 0.3867 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 352ms/step - loss: 0.3764 - val_loss: 0.3251 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 353ms/step - loss: 0.3171 - val_loss: 0.2743 - learning_rate: 1.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 350ms/step - loss: 0.2673 - val_loss: 0.2302 - learning_rate: 1.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 352ms/step - loss: 0.2255 - val_loss: 0.1960 - learning_rate: 1.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 376ms/step - loss: 0.1910 - val_loss: 0.1635 - learning_rate: 1.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 374ms/step - loss: 0.1614 - val_loss: 0.1392 - learning_rate: 1.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 353ms/step - loss: 0.1372 - val_loss: 0.1179 - learning_rate: 1.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 351ms/step - loss: 0.1172 - val_loss: 0.0994 - learning_rate: 1.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 354ms/step - loss: 0.0999 - val_loss: 0.0871 - learning_rate: 1.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 351ms/step - loss: 0.0864 - val_loss: 0.0732 - learning_rate: 1.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 353ms/step - loss: 0.0745 - val_loss: 0.0628 - learning_rate: 1.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 364ms/step - loss: 0.0648 - val_loss: 0.0551 - learning_rate: 1.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 345ms/step - loss: 0.0569 - val_loss: 0.0491 - learning_rate: 1.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 347ms/step - loss: 0.0501 - val_loss: 0.0441 - learning_rate: 1.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 347ms/step - loss: 0.0448 - val_loss: 0.0393 - learning_rate: 1.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 347ms/step - loss: 0.0399 - val_loss: 0.0336 - learning_rate: 1.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 346ms/step - loss: 0.0363 - val_loss: 0.0314 - learning_rate: 1.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 347ms/step - loss: 0.0329 - val_loss: 0.0280 - learning_rate: 1.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 347ms/step - loss: 0.0302 - val_loss: 0.0261 - learning_rate: 1.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 349ms/step - loss: 0.0283 - val_loss: 0.0237 - learning_rate: 1.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 347ms/step - loss: 0.0263 - val_loss: 0.0224 - learning_rate: 1.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 348ms/step - loss: 0.0245 - val_loss: 0.0208 - learning_rate: 1.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 349ms/step - loss: 0.0231 - val_loss: 0.0191 - learning_rate: 1.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 366ms/step - loss: 0.0217 - val_loss: 0.0186 - learning_rate: 1.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 370ms/step - loss: 0.0207 - val_loss: 0.0179 - learning_rate: 1.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 377ms/step - loss: 0.0198 - val_loss: 0.0166 - learning_rate: 1.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 363ms/step - loss: 0.0187 - val_loss: 0.0162 - learning_rate: 1.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 368ms/step - loss: 0.0180 - val_loss: 0.0153 - learning_rate: 1.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 391ms/step - loss: 0.0171 - val_loss: 0.0146 - learning_rate: 1.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m17/36\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 341ms/step - loss: 0.0168"
     ]
    }
   ],
   "source": [
    "# Train the model with a larger batch size (128)\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=128, validation_data=(X_test, y_test),\n",
    "                    callbacks=[early_stopping, reduce_lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69c9978-2980-4e0e-8247-92407aa37715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('lstm_temperature_humidity_model.h5')  # Save the model to a file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bd87cc-bced-4607-9fa2-b9b9684a6208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeafd30f-06b7-49cd-ad1f-7d9892513f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48af3ff5-e07f-4060-b792-1363a9c09870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse scaling to get actual temperature and humidity values\n",
    "predicted_temp = scaler_temp.inverse_transform(predictions[:, :7])\n",
    "predicted_hum = scaler_hum.inverse_transform(predictions[:, 7:])\n",
    "actual_temp = scaler_temp.inverse_transform(y_test[:, :7])\n",
    "actual_hum = scaler_hum.inverse_transform(y_test[:, 7:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b321eb-b240-4fd1-87e9-59996584166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RMSE for temperature and humidity\n",
    "rmse_temp = np.sqrt(mean_squared_error(actual_temp, predicted_temp))\n",
    "rmse_hum = np.sqrt(mean_squared_error(actual_hum, predicted_hum))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfa3077-fbca-4280-9e06-8fadcadfab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy percentage\n",
    "accuracy_temp = (1 - rmse_temp / np.mean(actual_temp)) * 100\n",
    "accuracy_hum = (1 - rmse_hum / np.mean(actual_hum)) * 100\n",
    "\n",
    "print(f\"Temperature RMSE: {rmse_temp:.2f}\")\n",
    "print(f\"Humidity RMSE: {rmse_hum:.2f}\")\n",
    "print(f\"Temperature Accuracy: {accuracy_temp:.2f}%\")\n",
    "print(f\"Humidity Accuracy: {accuracy_hum:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5183fb60-19b0-4d8a-8a23-814d5d4c054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f02f16e-7b48-459a-a78f-269157e5deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs predicted temperature\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(predicted_temp[:, 0], label='Predicted Temperature')\n",
    "plt.plot(actual_temp[:, 0], label='Actual Temperature')\n",
    "plt.legend()\n",
    "plt.title('Temperature: Predicted vs Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c688aa-8b1b-42df-9029-5888cd8a5777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs predicted humidity\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(predicted_hum[:, 0], label='Predicted Humidity')\n",
    "plt.plot(actual_hum[:, 0], label='Actual Humidity')\n",
    "plt.legend()\n",
    "plt.title('Humidity: Predicted vs Actual')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
